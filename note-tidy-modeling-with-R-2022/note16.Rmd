---
title: "note16"
output: html_notebook
---

```{r}
options(paged.print = FALSE)
```

# 16 차원 축소

## 16.2 한 장의 그림은 천 개의 가치가 있습니다... 콩

```{r}
library(tidymodels)
tidymodels_prefer()
library(beans)
```

```{r}
set.seed(1601)
bean_split <- initial_split(beans, strata = class, prop = 3 / 4)
bean_train <- training(bean_split)
bean_test <- testing(bean_split)

set.seed(1602)
bean_val <- validation_split(bean_train, strata = class, prop = 4 / 5)
bean_val$splits[[1]]
```

```{r}
# install.packages("corrplot")
library(corrplot)
tmwr_cols <- colorRampPalette(c("#91CBD765", "#CA225E"))
bean_train %>%
  select(-class) %>%
  cor() %>%
  corrplot(method = "ellipse", tl.col = "black", col = tmwr_cols(200))
```

## 16.3 스타터 레시피

```{r}
# install.packages("bestNormalize")
library(bestNormalize)

bean_rec <-
  analysis(bean_val$splits[[1]]) %>%
  recipe(class ~ .) %>%
  step_zv(all_numeric_predictors()) %>%
  step_orderNorm(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors())
```

## 16.4 야생의 조리법

```{r}
bean_rec_trained <- prep(bean_rec)
bean_rec_trained
```

```{r}
show_variables <-
  bean_rec %>%
  prep(log_changes = TRUE)
```

```{r}
bean_validation <- bean_val$splits %>%
  pluck(1) %>%
  assessment()
bean_val_processed <- bake(bean_rec_trained, new_data = bean_validation)
bean_val_processed
```

```{r}
library(patchwork)
p1 <-
  bean_validation %>%
  ggplot(aes(x = area)) +
  geom_histogram(bins = 30, color = "white", fill = "blue", alpha = 1 / 3) +
  ggtitle("Original validation set data")
p1

p2 <-
  bean_val_processed %>%
  ggplot(aes(x = area)) +
  geom_histogram(bins = 30, color = "white", fill = "red", alpha = 1 / 3) +
  ggtitle("Processed validation set data")

p1 + p2
```

```{r}
bean_validation
```

```{r}
bake(bean_rec_trained, new_data = NULL) %>% nrow()
bean_val$splits %>%
  pluck(1) %>%
  analysis() %>%
  nrow()
```

## 16.5 특징 추출 기법

```{r}
library(ggforce)
plot_validation_results <- function(recipe, dat = assessment(bean_val$splits[[1]])) {
  recipe %>%
    # Estimate any additional steps
    prep() %>%
    # Process the data (the validation set by default)
    bake(new_data = dat) %>%
    # Create the scatterplot matrix
    ggplot(aes(x = .panel_x, y = .panel_y, color = class, fill = class)) +
    geom_point(alpha = 0.4, size = 0.5) +
    geom_autodensity(alpha = .3) +
    facet_matrix(vars(-class), layer.diag = 2) +
    scale_color_brewer(palette = "Dark2") +
    scale_fill_brewer(palette = "Dark2")
}
```

```{r}
bean_rec_trained %>%
  step_pca(all_numeric_predictors(), num_comp = 4) %>%
  plot_validation_results() +
  ggtitle("Principal Component Analysis")
```

```{r}
# devtools::install_github("tidymodels/learntidymodels")
library(learntidymodels)
bean_rec_trained %>%
  step_pca(all_numeric_predictors(), num_comp = 4) %>%
  prep() %>%
  plot_top_loadings(component_number <= 4, n = 5) +
  scale_fill_brewer(palette = "Paired") +
  ggtitle("Principal Component Analysis") +
  theme_bw() +
  theme(legend.position = "top")
```

```{r}
# BiocManager::install('mixOmics')
bean_rec_trained %>%
  step_pls(all_numeric_predictors(), outcome = "class", num_comp = 4) %>%
  plot_validation_results() +
  ggtitle("Partial Least Squares")
```

```{r}
bean_rec_trained %>%
  step_pls(all_numeric_predictors(), outcome = "class", num_comp = 4) %>%
  prep() %>%
  plot_top_loadings(component_number <= 4, n = 5, type = "pls") +
  scale_fill_brewer(palette = "Paired") +
  ggtitle("Partial Least Squares")
```

```{r}
# install.packages("fastICA")
bean_rec_trained %>%
  step_ica(all_numeric_predictors(), num_comp = 4) %>%
  plot_validation_results() +
  ggtitle("Independent Component Analysis")
```

```{r}
library(embed)
bean_rec_trained %>%
  step_umap(all_numeric_predictors(), num_comp = 4) %>%
  plot_validation_results() +
  ggtitle("UMAP")
```

```{r}
bean_rec_trained %>%
  step_umap(all_numeric_predictors(), outcome = "class", num_comp = 4) %>%
  plot_validation_results() +
  ggtitle("UMAP (supervised)")
```

## 16.6 모델링

```{r}
library(baguette)
library(discrim)

mlp_spec <-
  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>%
  set_engine("nnet") %>%
  set_mode("classification")

bagging_spec <-
  bag_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

fda_spec <-
  discrim_flexible(
    prod_degree = tune()
  ) %>%
  set_engine("earth")

rda_spec <-
  discrim_regularized(frac_common_cov = tune(), frac_identity = tune()) %>%
  set_engine("klaR")

bayes_spec <-
  naive_Bayes() %>%
  set_engine("klaR")
```

```{r}
bean_rec <-
  recipe(class ~ ., data = bean_train) %>%
  step_zv(all_numeric_predictors()) %>%
  step_orderNorm(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors())

pls_rec <-
  bean_rec %>%
  step_pls(all_numeric_predictors(), outcome = "class", num_comp = tune())

umap_rec <-
  bean_rec %>%
  step_umap(
    all_numeric_predictors(),
    outcome = "class",
    num_comp = tune(),
    neighbors = tune(),
    min_dist = tune()
  )
```

```{r}
# library(doParallel)
# cl <- makePSOCKcluster(8)
# registerDoParallel(cl)
# stopCluster(cl)
# library(doMC)
# registerDoMC(cores = 8)
# 멀티로는 실행불가
# 하나씩 실행하는 것으로는 에러 발생

ctrl <- control_grid(parallel_over = "everything")
bean_res <-
  workflow_set(
    preproc = list(basic = class ~ ., pls = pls_rec, umap = umap_rec),
    models = list(
      bayes = bayes_spec, fda = fda_spec,
      rda = rda_spec, bag = bagging_spec,
      mlp = mlp_spec
    )
  ) %>%
  workflow_map(
    verbose = TRUE,
    seed = 1603,
    resamples = bean_val,
    grid = 10,
    metrics = metric_set(roc_auc) # ,
    # control = ctrl
  )
```

```{r}
rankings <-
  rank_results(bean_res, select_best = TRUE) %>%
  mutate(method = map_chr(wflow_id, ~ str_split(.x, "_", simplify = TRUE)[1]))

tidymodels_prefer()
filter(rankings, rank <= 5) %>% dplyr::select(rank, mean, model, method)
```

```{r}
rda_res <-
  bean_res %>%
  extract_workflow("pls_rda") %>%
  finalize_workflow(
    bean_res %>%
      extract_workflow_set_result("pls_rda") %>%
      select_best(metric = "roc_auc")
  ) %>%
  last_fit(split = bean_split, metrics = metric_set(roc_auc))

rda_wflow_fit <- extract_workflow(rda_res)
```

```{r}
collect_metrics(rda_res)
```
